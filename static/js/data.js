window.CONTENTBENCH_DATA = 
{
  "generated": "2025-07-16T02:35:42.964051",
  "dataset_info": {
    "total_posts": 117,
    "categories": 7
  },
  "models": [
    {
      "rank": 1,
      "model_name": "openai/chatgpt-4o-latest",
      "display_name": "GPT-4o model used in ChatGPT",
      "accuracy": 100.0,
      "posts_per_dollar": 566
    },
    {
      "rank": 2,
      "model_name": "openai/o3-high",
      "display_name": "o3 (High Reasoning)",
      "accuracy": 100.0,
      "posts_per_dollar": 411
    },
    {
      "rank": 3,
      "model_name": "anthropic/claude-opus-4",
      "display_name": "Claude Opus 4",
      "accuracy": 100.0,
      "posts_per_dollar": 167
    },
    {
      "rank": 4,
      "model_name": "google/gemini-2.5-pro",
      "display_name": "Gemini 2.5 Pro",
      "accuracy": 100.0,
      "posts_per_dollar": 96
    },
    {
      "rank": 5,
      "model_name": "openai/o3-low",
      "display_name": "o3 (Low Reasoning)",
      "accuracy": 97.44,
      "posts_per_dollar": 1024
    },
    {
      "rank": 6,
      "model_name": "gemini-2.5-flash",
      "display_name": "Gemini 2.5 Flash",
      "accuracy": 97.44,
      "posts_per_dollar": 780
    },
    {
      "rank": 7,
      "model_name": "meta-llama/llama-3.1-70b-instruct",
      "display_name": "Llama 3.1 70B",
      "accuracy": 95.73,
      "posts_per_dollar": 27777
    },
    {
      "rank": 8,
      "model_name": "google/gemini-2.5-flash-nothinking",
      "display_name": "Gemini 2.5 Flash (No Reasoning)",
      "accuracy": 95.73,
      "posts_per_dollar": 8771
    },
    {
      "rank": 9,
      "model_name": "google/gemini-2.0-flash-001",
      "display_name": "Gemini 2.0 Flash",
      "accuracy": 94.02,
      "posts_per_dollar": 27777
    },
    {
      "rank": 10,
      "model_name": "google/gemma-3-12b-it",
      "display_name": "Gemma 3 12B",
      "accuracy": 93.16,
      "posts_per_dollar": null
    },
    {
      "rank": 11,
      "model_name": "meta-llama/llama-3.3-70b-instruct",
      "display_name": "Llama 3.3 70B",
      "accuracy": 93.16,
      "posts_per_dollar": 71428
    },
    {
      "rank": 12,
      "model_name": "qwen/qwq-32b",
      "display_name": "QwQ 32B",
      "accuracy": 92.31,
      "posts_per_dollar": 10526
    },
    {
      "rank": 13,
      "model_name": "openai/gpt-4.1-mini",
      "display_name": "GPT-4.1 Mini",
      "accuracy": 92.31,
      "posts_per_dollar": 6993
    },
    {
      "rank": 14,
      "model_name": "nousresearch/hermes-3-llama-3.1-70b",
      "display_name": "Hermes 3 Llama 3.1 70B",
      "accuracy": 91.45,
      "posts_per_dollar": 27777
    },
    {
      "rank": 15,
      "model_name": "google/gemini-2.5-flash-lite-preview-06-17-thinking",
      "display_name": "Gemini 2.5 Flash-Lite (Reasoning)",
      "accuracy": 90.6,
      "posts_per_dollar": 1742
    },
    {
      "rank": 16,
      "model_name": "openai/gpt-4o",
      "display_name": "GPT-4o",
      "accuracy": 90.6,
      "posts_per_dollar": 1097
    },
    {
      "rank": 17,
      "model_name": "google/gemini-2.5-flash-lite-preview-06-17",
      "display_name": "Gemini 2.5 Flash-Lite",
      "accuracy": 89.74,
      "posts_per_dollar": 27777
    },
    {
      "rank": 18,
      "model_name": "openrouter/google/gemma-3-27b-it",
      "display_name": "Gemma 3 27B",
      "accuracy": 88.89,
      "posts_per_dollar": 30303
    },
    {
      "rank": 19,
      "model_name": "qwen/qwen-2.5-coder-32b-instruct",
      "display_name": "Qwen 2.5 Coder 32B",
      "accuracy": 88.89,
      "posts_per_dollar": 16129
    },
    {
      "rank": 20,
      "model_name": "qwen/qwen3-32b",
      "display_name": "Qwen3 32B",
      "accuracy": 88.89,
      "posts_per_dollar": 7142
    },
    {
      "rank": 21,
      "model_name": "google/gemma-3-27b-it",
      "display_name": "Gemma 3 27B",
      "accuracy": 88.03,
      "posts_per_dollar": null
    },
    {
      "rank": 22,
      "model_name": "microsoft/phi-4",
      "display_name": "Phi-4",
      "accuracy": 87.18,
      "posts_per_dollar": 41666
    },
    {
      "rank": 23,
      "model_name": "mistralai/mistral-small-3.2-24b-instruct",
      "display_name": "Mistral-Small-3.2-24B",
      "accuracy": 86.32,
      "posts_per_dollar": 28571
    },
    {
      "rank": 24,
      "model_name": "qwen/qwen3-30b-a3b",
      "display_name": "Qwen3 30B A3B",
      "accuracy": 86.32,
      "posts_per_dollar": 5434
    },
    {
      "rank": 25,
      "model_name": "meta-llama/llama-4-scout",
      "display_name": "Llama 4 Scout",
      "accuracy": 85.47,
      "posts_per_dollar": 34482
    },
    {
      "rank": 26,
      "model_name": "qwen/qwen3-14b",
      "display_name": "Qwen3 14B",
      "accuracy": 85.47,
      "posts_per_dollar": 8474
    },
    {
      "rank": 27,
      "model_name": "mistralai/mistral-small-24b-instruct-2501",
      "display_name": "Mistral Small 24B (2501)",
      "accuracy": 84.62,
      "posts_per_dollar": 58823
    },
    {
      "rank": 28,
      "model_name": "deepseek/deepseek-r1-distill-llama-70b",
      "display_name": "DeepSeek R1 Distill Llama 70B",
      "accuracy": 83.76,
      "posts_per_dollar": 5347
    },
    {
      "rank": 29,
      "model_name": "mistralai/devstral-small",
      "display_name": "Devstral Small",
      "accuracy": 82.91,
      "posts_per_dollar": 31250
    },
    {
      "rank": 30,
      "model_name": "mistralai/devstral-small-2505",
      "display_name": "Devstral Small (2505)",
      "accuracy": 82.05,
      "posts_per_dollar": 47619
    },
    {
      "rank": 31,
      "model_name": "thudm/glm-4.1v-9b-thinking",
      "display_name": "GLM 4.1v 9B Thinking",
      "accuracy": 81.2,
      "posts_per_dollar": 16129
    },
    {
      "rank": 32,
      "model_name": "google/gemini-2.0-flash-lite-001",
      "display_name": "Gemini 2.0 Flash Lite",
      "accuracy": 80.34,
      "posts_per_dollar": 37037
    },
    {
      "rank": 33,
      "model_name": "mistralai/mistral-small-3.1-24b-instruct",
      "display_name": "Mistral-Small-3.1-24B",
      "accuracy": 80.34,
      "posts_per_dollar": 28571
    },
    {
      "rank": 34,
      "model_name": "openai/gpt-4o-mini",
      "display_name": "GPT-4o mini",
      "accuracy": 80.34,
      "posts_per_dollar": 18518
    },
    {
      "rank": 35,
      "model_name": "qwen/qwen3-8b",
      "display_name": "Qwen3 8B",
      "accuracy": 80.34,
      "posts_per_dollar": 7407
    },
    {
      "rank": 36,
      "model_name": "openai/gpt-3.5-turbo",
      "display_name": "GPT-3.5 Turbo",
      "accuracy": 80.34,
      "posts_per_dollar": 5617
    },
    {
      "rank": 37,
      "model_name": "mistralai/magistral-small-2506",
      "display_name": "Magistral Small 2506",
      "accuracy": 79.49,
      "posts_per_dollar": 28571
    },
    {
      "rank": 38,
      "model_name": "google/gemma-3n-e4b-it",
      "display_name": "Gemma 3N E4B",
      "accuracy": 78.63,
      "posts_per_dollar": null
    },
    {
      "rank": 39,
      "model_name": "qwen/qwen-turbo",
      "display_name": "Qwen Turbo",
      "accuracy": 78.63,
      "posts_per_dollar": 55555
    },
    {
      "rank": 40,
      "model_name": "mistralai/mistral-nemo",
      "display_name": "Mistral Nemo",
      "accuracy": 77.78,
      "posts_per_dollar": 333333
    },
    {
      "rank": 41,
      "model_name": "mistralai/pixtral-12b",
      "display_name": "Pixtral 12B",
      "accuracy": 77.78,
      "posts_per_dollar": 29411
    },
    {
      "rank": 42,
      "model_name": "meta-llama/llama-3.1-8b-instruct",
      "display_name": "Llama 3.1 8B",
      "accuracy": 76.92,
      "posts_per_dollar": 199999
    },
    {
      "rank": 43,
      "model_name": "deepseek/deepseek-r1-0528-qwen3-8b",
      "display_name": "DeepSeek R1 Qwen3 8B",
      "accuracy": 76.92,
      "posts_per_dollar": 83333
    },
    {
      "rank": 44,
      "model_name": "amazon/nova-lite-v1",
      "display_name": "Amazon Nova Lite",
      "accuracy": 76.92,
      "posts_per_dollar": 47619
    },
    {
      "rank": 45,
      "model_name": "mistralai/mixtral-8x7b-instruct",
      "display_name": "Mixtral 8x7B",
      "accuracy": 76.92,
      "posts_per_dollar": 28571
    },
    {
      "rank": 46,
      "model_name": "mistralai/mistral-7b-instruct",
      "display_name": "Mistral 7B",
      "accuracy": 76.07,
      "posts_per_dollar": 19230
    },
    {
      "rank": 47,
      "model_name": "deepseek/deepseek-r1-distill-qwen-32b",
      "display_name": "DeepSeek R1 Distill Qwen 32B",
      "accuracy": 76.07,
      "posts_per_dollar": 11494
    },
    {
      "rank": 48,
      "model_name": "mistralai/mistral-7b-instruct-v0.3",
      "display_name": "Mistral 7B v0.3",
      "accuracy": 74.36,
      "posts_per_dollar": 90909
    },
    {
      "rank": 49,
      "model_name": "google/gemma-3-4b-it",
      "display_name": "Gemma 3 4B",
      "accuracy": 73.5,
      "posts_per_dollar": null
    },
    {
      "rank": 50,
      "model_name": "nousresearch/hermes-2-pro-llama-3-8b",
      "display_name": "Hermes 2 Pro Llama 3 8B",
      "accuracy": 73.5,
      "posts_per_dollar": 111111
    },
    {
      "rank": 51,
      "model_name": "amazon/nova-micro-v1",
      "display_name": "Amazon Nova Micro",
      "accuracy": 73.5,
      "posts_per_dollar": 83333
    },
    {
      "rank": 52,
      "model_name": "meta-llama/llama-3.2-11b-vision-instruct",
      "display_name": "Llama 3.2 11B Vision",
      "accuracy": 73.5,
      "posts_per_dollar": 58823
    },
    {
      "rank": 53,
      "model_name": "microsoft/phi-3-mini-128k-instruct",
      "display_name": "Phi 3 Mini 128k",
      "accuracy": 72.65,
      "posts_per_dollar": 24999
    },
    {
      "rank": 54,
      "model_name": "meta-llama/llama-3-8b-instruct",
      "display_name": "Llama 3 8B",
      "accuracy": 71.79,
      "posts_per_dollar": 90909
    },
    {
      "rank": 55,
      "model_name": "sao10k/l3-lunaris-8b",
      "display_name": "L3 Lunaris 8B",
      "accuracy": 70.94,
      "posts_per_dollar": 142857
    },
    {
      "rank": 56,
      "model_name": "microsoft/phi-3.5-mini-128k-instruct",
      "display_name": "Phi 3.5 Mini 128k",
      "accuracy": 70.94,
      "posts_per_dollar": 24999
    },
    {
      "rank": 57,
      "model_name": "qwen/qwen-2.5-7b-instruct",
      "display_name": "Qwen 2.5 7B",
      "accuracy": 67.52,
      "posts_per_dollar": 71428
    },
    {
      "rank": 58,
      "model_name": "microsoft/phi-4-reasoning-plus",
      "display_name": "Phi-4 Reasoning+",
      "accuracy": 67.52,
      "posts_per_dollar": 40000
    },
    {
      "rank": 59,
      "model_name": "openai/gpt-4.1-nano",
      "display_name": "GPT-4.1 Nano",
      "accuracy": 65.81,
      "posts_per_dollar": 27777
    },
    {
      "rank": 60,
      "model_name": "meta-llama/llama-3.2-3b-instruct",
      "display_name": "Llama 3.2 3B",
      "accuracy": 64.1,
      "posts_per_dollar": 1000000
    },
    {
      "rank": 61,
      "model_name": "meta-llama/llama-guard-3-8b",
      "display_name": "Llama Guard 3 8B",
      "accuracy": 62.07,
      "posts_per_dollar": 3472
    },
    {
      "rank": 62,
      "model_name": "gryphe/mythomax-l2-13b",
      "display_name": "MythoMax L2 13B",
      "accuracy": 61.54,
      "posts_per_dollar": 1295
    },
    {
      "rank": 63,
      "model_name": "microsoft/phi-4-multimodal-instruct",
      "display_name": "Phi-4 Multimodal",
      "accuracy": 59.83,
      "posts_per_dollar": 58823
    },
    {
      "rank": 64,
      "model_name": "cohere/command-r7b-12-2024",
      "display_name": "Command R 7B",
      "accuracy": 58.12,
      "posts_per_dollar": 71428
    },
    {
      "rank": 65,
      "model_name": "mistralai/ministral-8b",
      "display_name": "Ministral 8B",
      "accuracy": 56.41,
      "posts_per_dollar": 29411
    },
    {
      "rank": 66,
      "model_name": "mistralai/ministral-3b",
      "display_name": "Ministral 3B",
      "accuracy": 54.7,
      "posts_per_dollar": 76923
    },
    {
      "rank": 67,
      "model_name": "liquid/lfm-7b",
      "display_name": "LFM 7B",
      "accuracy": 50.43,
      "posts_per_dollar": 250000
    },
    {
      "rank": 68,
      "model_name": "deepseek/deepseek-r1-distill-llama-8b",
      "display_name": "DeepSeek R1 Distill Llama 8B",
      "accuracy": 49.57,
      "posts_per_dollar": 34482
    },
    {
      "rank": 69,
      "model_name": "liquid/lfm-3b",
      "display_name": "LFM 3B",
      "accuracy": 41.03,
      "posts_per_dollar": 142857
    },
    {
      "rank": 70,
      "model_name": "deepseek/deepseek-r1-distill-qwen-7b",
      "display_name": "DeepSeek R1 Distill Qwen 7B",
      "accuracy": 32.48,
      "posts_per_dollar": 9259
    },
    {
      "rank": 71,
      "model_name": "meta-llama/llama-3.2-1b-instruct",
      "display_name": "Llama 3.2 1B",
      "accuracy": 17.09,
      "posts_per_dollar": 500000
    },
    {
      "rank": 72,
      "model_name": "google/gemma-3-1b-it",
      "display_name": "Gemma 3 1B",
      "accuracy": 15.38,
      "posts_per_dollar": null
    }
  ]
}